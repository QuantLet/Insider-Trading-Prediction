{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4a24cc-6d17-4ff2-b64e-5640e8f0314c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f\n",
    "import numpy as np                             # Import NumPy library for numerical computation and array operations\n",
    "import pandas as pd                            # Import Pandas library for data manipulation and analysis\n",
    "import matplotlib.pyplot as plt                # Import Matplotlib library for data visualization\n",
    "from concurrent.futures import ProcessPoolExecutor  # Parallel processing\n",
    "import os, gc, time, zipfile                   # Import os module for file path operations\n",
    "from tqdm import tqdm                          # Import tqdm library for progress bar display\n",
    "from datetime import datetime                  # Import datetime module for time-related operations\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import umap.umap_ as umap\n",
    "import umap\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "# Import custom module or function\n",
    "from init_project_environment import init_project_environment\n",
    "init_project_environment()\n",
    "\n",
    "# ============ Project Path Configuration ============\n",
    "project_root = os.path.abspath(\".\")            # Get the absolute path of the current project root directory\n",
    "data_dir = os.path.join(project_root, \"A_Data\")       # Concatenate the path for the data folder\n",
    "log_dir = os.path.join(project_root, \"B_log\")\n",
    "result_dir = os.path.join(project_root, \"D_Result\")   # Concatenate the path for the result output folder\n",
    "model_dir = os.path.join(project_root, \"C_Model\")\n",
    "saved_models = os.path.join(project_root, \"saved_models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9669e89-0849-429e-a771-13b21402f92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Step 1: Read Data ===\n",
    "data_path = os.path.join(data_dir, \"lag_merged_all.parquet\")\n",
    "df = pd.read_parquet(data_path)\n",
    "\n",
    "# Remove unnecessary columns\n",
    "drop_cols = [\"Estbdt_13_lag\", \"Ipodt_13_lag\", \"Province_lag\"]\n",
    "df.drop(columns=drop_cols, inplace=True, errors=\"ignore\")\n",
    "\n",
    "# === Step 2: Separate X, y, and ID ===\n",
    "y = df[\"insider_trading\"]\n",
    "id_cols = [\"Stkcd\", \"Trddt\"]\n",
    "X = df.drop(columns=[\"insider_trading\"] + id_cols, errors=\"ignore\")\n",
    "\n",
    "# X_sample = X\n",
    "# y_sample = y\n",
    "\n",
    "# === Step 3: Separate positive and negative samples ===\n",
    "# Keep all positive samples (1) and randomly sample a subset of negative samples (0)\n",
    "df_pos, y_pos = X[y == 1], y[y == 1]\n",
    "df_neg, y_neg = X[y == 0], y[y == 0]\n",
    "\n",
    "# === General Settings ===\n",
    "n_runs  = 5\n",
    "seed = 42\n",
    "rng = np.random.RandomState(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6707c5f5-f580-4641-8143-03c5cf07bc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total number of unique stocks\n",
    "total_stocks = df[\"Stkcd\"].nunique()\n",
    "\n",
    "# Stocks that have experienced at least one insider trading incident (label == 1)\n",
    "stocks_with_insider = df[df[\"insider_trading\"] == 1][\"Stkcd\"].unique()\n",
    "num_stocks_with_insider = len(stocks_with_insider)\n",
    "\n",
    "# Stocks that have never experienced insider trading (label always == 0)\n",
    "all_stocks = df[\"Stkcd\"].unique()\n",
    "stocks_without_insider = np.setdiff1d(all_stocks, stocks_with_insider)\n",
    "num_stocks_without_insider = len(stocks_without_insider)\n",
    "\n",
    "# Total number of samples (i.e., trading day records)\n",
    "total_samples = len(df)\n",
    "\n",
    "# Number of insider trading samples (label == 1)\n",
    "num_positive = (df[\"insider_trading\"] == 1).sum()\n",
    "\n",
    "# Number of non-insider trading samples (label == 0)\n",
    "num_negative = (df[\"insider_trading\"] == 0).sum()\n",
    "\n",
    "# Print results\n",
    "print(f\"Total number of stocks: {total_stocks}\")\n",
    "print(f\"Stocks with at least one insider trading incident: {num_stocks_with_insider}\")\n",
    "print(f\"Stocks with no insider trading incidents: {num_stocks_without_insider}\")\n",
    "print(f\"Total number of samples (trading days): {total_samples}\")\n",
    "print(f\"Number of insider trading samples (label = 1): {num_positive}\")\n",
    "print(f\"Number of non-insider trading samples (label = 0): {num_negative}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4694cd6e-8937-4b67-9b96-2d9ef2326b70",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Only PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9a99f1-e69f-41e5-b2f8-245f9a06db39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import resample\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Set output directory for saving figures\n",
    "out_dir = \"/root/autodl-tmp/UMAP_fig_20250928/OnlyPCA\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "# Define sampling ratios\n",
    "sampling_ratios = [1, 2, 5]\n",
    "n_runs = 10  # Number of repeated runs for each sampling ratio\n",
    "\n",
    "for ratio in sampling_ratios:\n",
    "    for run in range(1, n_runs + 1):\n",
    "        n_pos = len(df_pos)\n",
    "        n_neg = int(n_pos * ratio)  # Calculate the number of negative samples\n",
    "\n",
    "        # resampling\n",
    "        df_neg_resampled, y_neg_resampled = resample(df_neg, y_neg, n_samples=n_neg, random_state=42+run)\n",
    "\n",
    "        # Combine positive and negative samples\n",
    "        df_sampled = pd.concat([df_pos, df_neg_resampled], axis=0)\n",
    "        y_sampled = pd.concat([y_pos, y_neg_resampled], axis=0)\n",
    "        print(y_sampled.value_counts())\n",
    "\n",
    "        # Step 1: Data cleaning – replace NaN/inf values with 0 and standardize the dataset\n",
    "        df_sampled = df_sampled.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "        scaler = StandardScaler()\n",
    "        df_scaled = scaler.fit_transform(df_sampled)  # Standardize data\n",
    "\n",
    "        # Step 2: PCA dimensionality reduction (set n_components=2 for visualization)\n",
    "        pca = PCA(n_components=2)\n",
    "        pca_result = pca.fit_transform(df_scaled)\n",
    "\n",
    "        # Step 3: Visualization\n",
    "        colors = np.where(y_sampled == 1, 'red', 'black')\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        # Keep equal aspect ratio for both axes\n",
    "        scatter = plt.scatter(pca_result[:, 0], pca_result[:, 1], c=colors, alpha=0.5,s=5)\n",
    "        legend_handles = [\n",
    "            plt.Line2D([0], [0], marker='o', color='w', label='Non-Insider Trading (0)', markerfacecolor='black', markersize=6),\n",
    "            plt.Line2D([0], [0], marker='o', color='w', label='Insider Trading (1)', markerfacecolor='red', markersize=6)\n",
    "        ]\n",
    "        plt.legend(handles=legend_handles, loc='upper center', bbox_to_anchor=(0.5, -0.1), ncol=2, fontsize=10, frameon=False)\n",
    "        plt.title(f'PCA Visualization - Sample {ratio}:1 - Run {run}')\n",
    "        plt.xlabel('Principal Component 1')\n",
    "        plt.ylabel('Principal Component 2')\n",
    "\n",
    "        #  Save figure with transparent background\n",
    "        out_path = os.path.join(out_dir, f\"OnlyPCA_{ratio}_run{run}.png\")\n",
    "        plt.savefig(out_path, dpi=300, bbox_inches=\"tight\", transparent=True)\n",
    "        plt.show()\n",
    "        print(f\"Run {run} completed and figure saved to {out_path}\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b784319-544e-4a1b-ae5f-5e8d30308b99",
   "metadata": {},
   "source": [
    "### Only t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b831ba-5904-4995-bd63-812f4f9a1b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import resample\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Set output directory\n",
    "out_dir = \"/root/autodl-tmp/UMAP_fig_20250928/Onlyt-SNE\"\n",
    "#shutil.rmtree(out_dir)  # Remove all contents in the specified folder\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "# Define sampling ratios (negatives per positive)\n",
    "sampling_ratios = [1, 2, 5]\n",
    "n_runs = 10  # 10 resamples for each ratio\n",
    "random_state =42\n",
    "\n",
    "for ratio in sampling_ratios:\n",
    "    for run in range(1, n_runs + 1):\n",
    "        # Sampling: resample the negative class to achieve the desired class ratio\n",
    "        n_pos = len(df_pos)\n",
    "        n_neg = int(n_pos * ratio)  # Compute the number of negative samples\n",
    "\n",
    "        # resampling\n",
    "        df_neg_resampled, y_neg_resampled = resample(df_neg, y_neg, n_samples=n_neg, random_state=42+run)\n",
    "\n",
    "        # Combine positive and resampled negative samples\n",
    "        df_sampled = pd.concat([df_pos, df_neg_resampled], axis=0)\n",
    "        y_sampled = pd.concat([y_pos, y_neg_resampled], axis=0)\n",
    "        print(y_sampled.value_counts())\n",
    "\n",
    "        # Step 1: Data cleaning—replace NaNs with 0 and standardize\n",
    "        df_sampled = df_sampled.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "        scaler = StandardScaler()\n",
    "        df_scaled = scaler.fit_transform(df_sampled)  # Standardize features\n",
    "\n",
    "        # Step 2: Dimensionality reduction with t-SNE\n",
    "        tsne = TSNE(n_components=2, random_state=random_state, perplexity=30)  # 可以调整perplexity和其他参数\n",
    "        tsne_result = tsne.fit_transform(df_scaled)  # 使用t-SNE进行降维\n",
    "\n",
    "        # Step 3: Visualization\n",
    "        colors = np.where(y_sampled == 1, 'red', 'black')\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        # Keep equal aspect ratio for the axes\n",
    "        plt.gca().set_aspect('equal', adjustable='box')\n",
    "        scatter = plt.scatter(tsne_result[:, 0], tsne_result[:, 1], c=colors, alpha=0.5, s=5)\n",
    "        legend_handles = [\n",
    "            plt.Line2D([0], [0], marker='o', color='w', label='Non-Insider Trading (0)', markerfacecolor='black', markersize=6),\n",
    "            plt.Line2D([0], [0], marker='o', color='w', label='Insider Trading (1)', markerfacecolor='red', markersize=6)\n",
    "        ]\n",
    "        plt.legend(handles=legend_handles, loc='upper center', bbox_to_anchor=(0.5, -0.1), ncol=2, fontsize=10, frameon=False)\n",
    "        plt.title(f't-SNE Visualization - Sample {ratio}:1 - Run {run}')\n",
    "        plt.xlabel('t-SNE Component 1')\n",
    "        plt.ylabel('t-SNE Component 2')\n",
    "\n",
    "        # Save the figure with a transparent background\n",
    "        out_path = os.path.join(out_dir, f\"Onlyt-SNE_{ratio}_per30_run{run}.png\")\n",
    "        plt.savefig(out_path, dpi=300, bbox_inches=\"tight\", transparent=True)\n",
    "        plt.show()\n",
    "        print(f\"Completed run {run} and saved figure to {out_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8af0b8-813e-499b-9bf6-430bf71848a5",
   "metadata": {},
   "source": [
    "### Only UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad75c54-c953-4f3c-8fd3-7eb47a684244",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from umap import UMAP\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import resample\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Set output directory\n",
    "out_dir = \"/root/autodl-tmp/UMAP_fig_20250928/OnlyUMAP\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "# # Define sampling ratios \n",
    "sampling_ratios = [1, 2, 5]\n",
    "n_runs = 5        # number of resamples per ratio\n",
    "random_state = 42\n",
    "n_neighbors_values = [15, 50, 100, 5, 10]\n",
    "\n",
    "for ratio in sampling_ratios:\n",
    "    for run in range(1, n_runs + 1):\n",
    "        # Sampling: resample the negative class to achieve the desired class balance\n",
    "        n_pos = len(df_pos)\n",
    "        n_neg = int(n_pos * ratio)  # number of negative samples\n",
    "\n",
    "        # resampling\n",
    "        df_neg_resampled, y_neg_resampled = resample(df_neg, y_neg, n_samples=n_neg, random_state=42 + run)\n",
    "\n",
    "        # Combine positive and resampled negative samples\n",
    "        df_sampled = pd.concat([df_pos, df_neg_resampled], axis=0)\n",
    "        y_sampled = pd.concat([y_pos, y_neg_resampled], axis=0)\n",
    "        print(y_sampled.value_counts())\n",
    "\n",
    "        # Step 1: Data cleaning—replace NaN/Inf and standardize\n",
    "        df_sampled = df_sampled.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "        scaler = StandardScaler()\n",
    "        df_scaled = scaler.fit_transform(df_sampled)  # standardize features\n",
    "\n",
    "        for n_neighbors in n_neighbors_values:\n",
    "            # Step 2: Dimensionality reduction with UMAP \n",
    "            umap = UMAP(n_components=2, random_state=random_state, n_neighbors=n_neighbors, min_dist=0.1)  # Set different values for the “n_neighbors” parameter.\n",
    "            umap_result = umap.fit_transform(df_scaled)  # fit UMAP and obtain 2D embedding\n",
    "\n",
    "            # Step 3: Visualization\n",
    "            colors = np.where(y_sampled == 1, 'red', 'black')\n",
    "            plt.figure(figsize=(6, 6))\n",
    "            # Keep equal aspect ratio for axes\n",
    "            plt.gca().set_aspect('equal', adjustable='box')\n",
    "            scatter = plt.scatter(umap_result[:, 0], umap_result[:, 1], c=colors, alpha=0.5, s=5)\n",
    "            legend_handles = [\n",
    "                plt.Line2D([0], [0], marker='o', color='w', label='Non-Insider Trading (0)', markerfacecolor='black', markersize=6),\n",
    "                plt.Line2D([0], [0], marker='o', color='w', label='Insider Trading (1)', markerfacecolor='red', markersize=6)\n",
    "            ]\n",
    "            plt.legend(handles=legend_handles, loc='upper center', bbox_to_anchor=(0.5, -0.1), ncol=2, fontsize=10, frameon=False)\n",
    "            plt.title(f'UMAP Visualization - Sample {ratio}:1 - Run {run} - n_neighbors={n_neighbors}')\n",
    "            plt.xlabel('UMAP Component 1')\n",
    "            plt.ylabel('UMAP Component 2')\n",
    "\n",
    "            # Save figure with transparent background\n",
    "            out_path = os.path.join(out_dir, f\"OnlyUMAP_{ratio}_n{n_neighbors}_run{run}.png\")\n",
    "            plt.savefig(out_path, dpi=300, bbox_inches=\"tight\", transparent=True)\n",
    "            plt.show()\n",
    "            print(f\"Completed run {run} and saved figure to {out_path}, n_neighbors={n_neighbors}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ae1a21-0f50-46e7-8e17-5ef3b01e5c09",
   "metadata": {},
   "source": [
    "### PCA then UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3e9675-c6b2-402e-92c2-89eaed951011",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from umap import UMAP\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA  # 引入PCA\n",
    "from sklearn.utils import resample\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Set output directory\n",
    "out_dir = \"/root/autodl-tmp/UMAP_fig_20250928/PCA+UMAP\"\n",
    "#shutil.rmtree(out_dir) # Remove all contents in the specified folder\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "# Define sampling ratios\n",
    "sampling_ratios = [1, 2, 5]\n",
    "n_runs = 5        # number of resamples per ratio\n",
    "random_state = 42\n",
    "n_neighbors_values = [15, 50, 100, 5, 10]  # can be set to multiple values\n",
    "# Variance retention threshold\n",
    "variance_threshold = 0.90  # retain 90% of variance\n",
    "\n",
    "for ratio in sampling_ratios:\n",
    "    for run in range(1, n_runs + 1):\n",
    "        # Sampling (resample the negative class to maintain the desired class ratio)\n",
    "        n_pos = len(df_pos)\n",
    "        n_neg = int(n_pos * ratio)  # compute the number of negative samples\n",
    "\n",
    "        df_neg_resampled, y_neg_resampled = resample(df_neg, y_neg, n_samples=n_neg, random_state=42 + run)\n",
    "\n",
    "        # Combine positive and resampled negative samples\n",
    "        df_sampled = pd.concat([df_pos, df_neg_resampled], axis=0)\n",
    "        y_sampled = pd.concat([y_pos, y_neg_resampled], axis=0)\n",
    "        print(y_sampled.value_counts())\n",
    "\n",
    "        # Step 1: Data cleaning—replace NaN/Inf with 0 and standardize\n",
    "        df_sampled = df_sampled.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "        scaler = StandardScaler()\n",
    "        df_scaled = scaler.fit_transform(df_sampled)  # standardize features\n",
    "\n",
    "        # Step 2: Apply PCA to retain 90% of the variance\n",
    "        pca = PCA(n_components=variance_threshold, random_state=random_state)  # retain 90% variance\n",
    "        pca_result = pca.fit_transform(df_scaled)\n",
    "        print(f\"Selected PCA components: {pca.n_components_}\")  # print the number of selected principal components\n",
    "\n",
    "        # Step 3: Further reduce with UMAP\n",
    "        for n_neighbors in n_neighbors_values:\n",
    "            umap = UMAP(n_components=2, random_state=random_state, n_neighbors=n_neighbors, min_dist=0.1)  # Set different values for the “n_neighbors” parameter\n",
    "            umap_result = umap.fit_transform(pca_result)  # apply UMAP on the PCA output\n",
    "\n",
    "            # Step 4: Visualization\n",
    "            colors = np.where(y_sampled == 1, 'red', 'black')\n",
    "            plt.figure(figsize=(6, 6))\n",
    "            # Keep equal aspect ratio for the axes\n",
    "            plt.gca().set_aspect('equal', adjustable='box')\n",
    "            scatter = plt.scatter(umap_result[:, 0], umap_result[:, 1], c=colors, alpha=0.5, s=5)\n",
    "            legend_handles = [\n",
    "                plt.Line2D([0], [0], marker='o', color='w', label='Non-Insider Trading (0)', markerfacecolor='black', markersize=6),\n",
    "                plt.Line2D([0], [0], marker='o', color='w', label='Insider Trading (1)', markerfacecolor='red', markersize=6)\n",
    "            ]\n",
    "            plt.legend(handles=legend_handles, loc='upper center', bbox_to_anchor=(0.5, -0.1), ncol=2, fontsize=10, frameon=False)\n",
    "            plt.title(f'PCA + UMAP Visualization - Sample {ratio}:1 - Run {run} - n_neighbors={n_neighbors}')\n",
    "            plt.xlabel('Component 1')\n",
    "            plt.ylabel('Component 2')\n",
    "\n",
    "            # Save the figure with a transparent background\n",
    "            out_path = os.path.join(out_dir, f\"PCA_UMAP_{ratio}_n{n_neighbors}_run{run}.png\")\n",
    "            plt.savefig(out_path, dpi=300, bbox_inches=\"tight\", transparent=True)  \n",
    "            plt.show() \n",
    "            print(f\"Completed run {run} and saved figure to {out_path}, n_neighbors={n_neighbors}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ab0f77-f9de-43be-ae64-7d896a2502b2",
   "metadata": {},
   "source": [
    "### PCA then t-SNE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700ecf6a-2f5f-4b92-aff7-5a951bd23d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA  # 引入PCA\n",
    "from sklearn.utils import resample\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Set output directory\n",
    "out_dir = \"/root/autodl-tmp/UMAP_fig_20250928/PCA+t-SNE\"\n",
    "#shutil.rmtree(out_dir) # 清空指定文件夹中的所有内容\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "# # Define sampling ratios\n",
    "sampling_ratios = [1, 2, 5]\n",
    "n_runs = 5       # number of resamples per ratio\n",
    "random_state = 42\n",
    "perplexity_values = [5, 10, 30, 50]\n",
    "# Variance retention threshold\n",
    "variance_threshold = 0.90  # retain 90% of the variance\n",
    "\n",
    "for ratio in sampling_ratios:\n",
    "    for run in range(1, n_runs + 1):\n",
    "        # Sampling: resample the negative class to maintain the desired class ratio\n",
    "        n_pos = len(df_pos)\n",
    "        n_neg = int(n_pos * ratio)  # compute the number of negative samples\n",
    "\n",
    "        df_neg_resampled, y_neg_resampled = resample(df_neg, y_neg, n_samples=n_neg, random_state=42 + run)\n",
    "\n",
    "        # Combine positive and resampled negative samples\n",
    "        df_sampled = pd.concat([df_pos, df_neg_resampled], axis=0)\n",
    "        y_sampled = pd.concat([y_pos, y_neg_resampled], axis=0)\n",
    "        print(y_sampled.value_counts())\n",
    "\n",
    "        # Step 1: Data cleaning—replace NaN/Inf with 0 and standardize\n",
    "        df_sampled = df_sampled.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "        scaler = StandardScaler()\n",
    "        df_scaled = scaler.fit_transform(df_sampled)  # standardize features\n",
    "\n",
    "        # Step 2: Apply PCA and retain 90% of the variance\n",
    "        pca = PCA(n_components=variance_threshold, random_state=random_state)  # retain 90% variance\n",
    "        pca_result = pca.fit_transform(df_scaled)\n",
    "\n",
    "        print(f\"Selected PCA components: {pca.n_components_}\")  # number of selected principal components\n",
    "\n",
    "        # Step 3: Further reduce with t-SNE\n",
    "        for perp in perplexity_values:\n",
    "            tsne = TSNE(n_components=2, perplexity=perp, learning_rate=\"auto\", n_iter=2000, init=\"pca\", random_state=42 + run )  # try different perplexity values\n",
    "            tsne_result = tsne.fit_transform(pca_result)  # apply t-SNE on the PCA output\n",
    "\n",
    "            # Step 4: Visualization\n",
    "            colors = np.where(y_sampled == 1, 'red', 'black')\n",
    "            plt.figure(figsize=(6, 6))\n",
    "            # Keep equal aspect ratio for the axes\n",
    "            plt.gca().set_aspect('equal', adjustable='box')\n",
    "            scatter = plt.scatter(tsne_result[:, 0], tsne_result[:, 1], c=colors, alpha=0.5, s=5)\n",
    "            legend_handles = [\n",
    "                plt.Line2D([0], [0], marker='o', color='w', label='Non-Insider Trading (0)', markerfacecolor='black', markersize=6),\n",
    "                plt.Line2D([0], [0], marker='o', color='w', label='Insider Trading (1)', markerfacecolor='red', markersize=6)\n",
    "            ]\n",
    "            plt.legend(handles=legend_handles, loc='upper center', bbox_to_anchor=(0.5, -0.1), ncol=2, fontsize=10, frameon=False)\n",
    "            plt.title(f'PCA + t-SNE Visualization - Sample {ratio}:1 - Run {run} - perplexity={perp}')\n",
    "            plt.xlabel('Component 1')\n",
    "            plt.ylabel('Component 2')\n",
    "\n",
    "            # Save the figure with a transparent background\n",
    "            out_path = os.path.join(out_dir, f\"PCA_tSNE_{ratio}_perp{perp}_run{run}.png\")\n",
    "            plt.savefig(out_path, dpi=300, bbox_inches=\"tight\", transparent=True)\n",
    "            plt.show()\n",
    "            print(f\"Completed run {run} and saved figure to {out_path}, perplexity={perp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba9d3c0-e19b-4a19-b1fc-7422867b97c1",
   "metadata": {},
   "source": [
    "### UMAP+ Leiden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1a865c-9efd-474e-b9e1-c3b1986ace36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from umap import UMAP\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import resample\n",
    "import igraph as ig\n",
    "import leidenalg\n",
    "import os\n",
    "\n",
    "# Set output directory\n",
    "out_dir = \"/root/autodl-tmp/UMAP_fig_20250928/UMAP+Leiden1029\"\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "# Parameters\n",
    "sampling_ratios = [1]\n",
    "n_runs = 5\n",
    "random_state = 42\n",
    "n_neighbors_values = [15]\n",
    "resolution_values = [0.05, 0.1, 0.2, 0.3, 0.4, 0.7, 1.0, 1.5]\n",
    "\n",
    "for ratio in sampling_ratios:\n",
    "    for run in range(1, n_runs + 1):\n",
    "        # Sampling: resample the negative class\n",
    "        n_pos = len(df_pos)\n",
    "        n_neg = int(n_pos * ratio)\n",
    "        df_neg_resampled, y_neg_resampled = resample(\n",
    "            df_neg, y_neg, n_samples=n_neg, random_state=random_state + run\n",
    "        )\n",
    "        df_sampled = pd.concat([df_pos, df_neg_resampled], axis=0)\n",
    "        y_sampled = pd.concat([y_pos, y_neg_resampled], axis=0)\n",
    "        print(y_sampled.value_counts())\n",
    "\n",
    "        # Clean and standardize\n",
    "        df_clean = df_sampled.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "        scaler = StandardScaler()\n",
    "        df_scaled = scaler.fit_transform(df_clean)\n",
    "\n",
    "        for n_neighbors in n_neighbors_values:\n",
    "            # UMAP reduction\n",
    "            umap_model = UMAP(\n",
    "                n_components=2,\n",
    "                random_state=random_state,\n",
    "                n_neighbors=n_neighbors,\n",
    "                min_dist=0.1,\n",
    "                metric='euclidean'\n",
    "            )\n",
    "            umap_result = umap_model.fit_transform(df_scaled)\n",
    "\n",
    "            # Build kNN graph & Leiden clustering\n",
    "            knn_graph = umap_model.graph_\n",
    "            sources, targets = knn_graph.nonzero()\n",
    "            weights = knn_graph.data\n",
    "            edges = list(zip(sources.tolist(), targets.tolist()))\n",
    "            g = ig.Graph(edges=edges, directed=False)\n",
    "            g.es['weight'] = weights\n",
    "\n",
    "            for resolution in resolution_values:\n",
    "                partition = leidenalg.find_partition(\n",
    "                    g,\n",
    "                    leidenalg.RBConfigurationVertexPartition,\n",
    "                    weights=g.es['weight'],\n",
    "                    resolution_parameter=resolution\n",
    "                )\n",
    "                cluster_labels = np.array(partition.membership)\n",
    "                n_clusters = len(set(cluster_labels))\n",
    "                print(f\"n_neighbors={n_neighbors}, resolution={resolution} → {n_clusters} clusters\")\n",
    "\n",
    "                # Visualization: clusters and true labels side by side\n",
    "                fig, axes = plt.subplots(1, 2, figsize=(12, 6), sharex=True, sharey=True)\n",
    "                # Left panel: clusters\n",
    "                sc0 = axes[0].scatter(\n",
    "                    umap_result[:, 0], umap_result[:, 1],\n",
    "                    c=cluster_labels, cmap='tab10', alpha=0.6, s=5\n",
    "                )\n",
    "                axes[0].set_title('Clusters Only')\n",
    "                axes[0].set_xlabel('UMAP Component 1')\n",
    "                axes[0].set_ylabel('UMAP Component 2')\n",
    "                axes[0].set_aspect('equal', 'box')\n",
    "                # Right panel: true labels\n",
    "                colors = np.where(y_sampled == 1, 'red', 'black')\n",
    "                axes[1].scatter(\n",
    "                    umap_result[:, 0], umap_result[:, 1],\n",
    "                    c=colors, alpha=0.4, s=5\n",
    "                )\n",
    "                axes[1].set_title('True Labels (Y)')\n",
    "                axes[1].set_xlabel('UMAP Component 1')\n",
    "                axes[1].set_ylabel('UMAP Component 2')\n",
    "                axes[1].set_aspect('equal', 'box')\n",
    "                # Add legend for true labels\n",
    "                legend_handles = [\n",
    "                    plt.Line2D([0], [0], marker='o', color='w', label='Non-Insider Trading (0)',\n",
    "                               markerfacecolor='black', markersize=6),\n",
    "                    plt.Line2D([0], [0], marker='o', color='w', label='Insider Trading (1)',\n",
    "                               markerfacecolor='red', markersize=6)\n",
    "                ]\n",
    "                axes[1].legend(handles=legend_handles, title='Legend', loc='best')\n",
    "\n",
    "                # Main title\n",
    "                fig.suptitle(\n",
    "                    f'UMAP + Leiden Clustering | Sample {ratio}:1 - Run {run}\\n' +\n",
    "                    f'n_neighbors={n_neighbors} - res={resolution} ({n_clusters} clusters)',\n",
    "                    fontsize=14\n",
    "                )\n",
    "\n",
    "                # Colorbar: align height with subplots\n",
    "                pos = axes[0].get_position()\n",
    "                cax = fig.add_axes([pos.x1 + 0.01, pos.y0, 0.02, pos.height])\n",
    "                fig.colorbar(sc0, cax=cax, label='Cluster ID')\n",
    "\n",
    "                # Save and show\n",
    "                path = os.path.join(\n",
    "                    out_dir,\n",
    "                    f\"UMAP_side_by_side_centerbar_{ratio}_n{n_neighbors}_run{run}_res{resolution}.png\"\n",
    "                )\n",
    "                plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "                plt.savefig(path, dpi=300, bbox_inches='tight', transparent=True)\n",
    "                plt.show()\n",
    "\n",
    "                # Visualization: cluster purity heatmap without numbers\n",
    "                df_eval = pd.DataFrame({'cluster': cluster_labels, 'true': y_sampled.values})\n",
    "                ct = pd.crosstab(df_eval['cluster'], df_eval['true'], normalize='index')\n",
    "                plt.figure(figsize=(8, 6))\n",
    "                sns.heatmap(\n",
    "                    ct,\n",
    "                    annot=False,\n",
    "                    cmap='Blues'\n",
    "                )\n",
    "                plt.xlabel('True Label (Y)')\n",
    "                plt.ylabel('Cluster ID')\n",
    "                plt.title(\n",
    "                    f'Cluster Purity Heatmap  |  Sample {ratio}:1 - Run {run} - ' +\n",
    "                    f'n_neighbors={n_neighbors} - res={resolution}'\n",
    "                )\n",
    "                path = os.path.join(\n",
    "                    out_dir,\n",
    "                    f\"cluster_purity_heatmap_{ratio}_n{n_neighbors}_run{run}_res{resolution}.png\"\n",
    "                )\n",
    "                plt.savefig(path, dpi=300, bbox_inches='tight', transparent=True)\n",
    "                plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
